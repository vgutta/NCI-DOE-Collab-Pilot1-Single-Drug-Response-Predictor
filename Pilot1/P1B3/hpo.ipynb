{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d976a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Multilayer Perceptron for drug response problem\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, LocallyConnected1D, Conv1D, MaxPooling1D, Flatten, Conv2D, LocallyConnected2D\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ProgbarLogger\n",
    "\n",
    "# For non-interactive plotting\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import p1b3 as benchmark\n",
    "import candle\n",
    "\n",
    "sys.argv = [''] # for Jupyter nbs\n",
    "\n",
    "#cfg = K.tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "#K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    "'''\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "'''\n",
    "\n",
    "## store results hpo\n",
    "training_stats = {}\n",
    "global tmp_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04661576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(default_model = 'p1b3_default_model.txt'):\n",
    "    \n",
    "    # Build benchmark object\n",
    "    p1b3Bmk = benchmark.BenchmarkP1B3(benchmark.file_path, default_model, 'keras',\n",
    "    prog='p1b3_baseline', desc='Multi-task (DNN) for data extraction from clinical reports - Pilot 3 Benchmark 1')\n",
    "    \n",
    "    \n",
    "    # Initialize parameters\n",
    "    gParameters = candle.finalize_parameters(p1b3Bmk)\n",
    "    #benchmark.logger.info('Params: {}'.format(gParameters))\n",
    "\n",
    "    return gParameters\n",
    "\n",
    "def str2lst(string_val):\n",
    "    result = [int(x) for x in string_val.split(' ')]\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate_keras_metric(y_true, y_pred, metric):\n",
    "    objective_function = metrics.get(metric)\n",
    "    objective = objective_function(y_true, y_pred)\n",
    "    return K.eval(objective)\n",
    "\n",
    "\n",
    "def evaluate_model(model, generator, steps, metric, category_cutoffs=[0.]):\n",
    "    y_true, y_pred = None, None\n",
    "    count = 0\n",
    "    while count < steps:\n",
    "        x_batch, y_batch = next(generator)\n",
    "        y_batch_pred = model.predict_on_batch(x_batch)\n",
    "        y_batch_pred = y_batch_pred.ravel()\n",
    "        y_true = np.concatenate((y_true, y_batch)) if y_true is not None else y_batch\n",
    "        y_pred = np.concatenate((y_pred, y_batch_pred)) if y_pred is not None else y_batch_pred\n",
    "        count += 1\n",
    "\n",
    "    loss = evaluate_keras_metric(y_true.astype(np.float32), y_pred.astype(np.float32), metric)\n",
    "\n",
    "    y_true_class = np.digitize(y_true, category_cutoffs)\n",
    "    y_pred_class = np.digitize(y_pred, category_cutoffs)\n",
    "\n",
    "    # theano does not like integer input\n",
    "    acc = evaluate_keras_metric(y_true_class.astype(np.float32), y_pred_class.astype(np.float32), 'binary_accuracy')  # works for multiclass labels as well\n",
    "\n",
    "    return loss, acc, y_true, y_pred, y_true_class, y_pred_class\n",
    "\n",
    "\n",
    "def plot_error(y_true, y_pred, batch, file_ext, file_pre='output_dir', subsample=1000):\n",
    "    if batch % 10:\n",
    "        return\n",
    "\n",
    "    total = len(y_true)\n",
    "    if subsample and subsample < total:\n",
    "        usecols = np.random.choice(total, size=subsample, replace=False)\n",
    "        y_true = y_true[usecols]\n",
    "        y_pred = y_pred[usecols]\n",
    "\n",
    "    y_true = y_true * 100\n",
    "    y_pred = y_pred * 100\n",
    "    diffs = y_pred - y_true\n",
    "\n",
    "    bins = np.linspace(-200, 200, 100)\n",
    "    if batch == 0:\n",
    "        y_shuf = np.random.permutation(y_true)\n",
    "        plt.hist(y_shuf - y_true, bins, alpha=0.5, label='Random')\n",
    "\n",
    "    #plt.hist(diffs, bins, alpha=0.35-batch/100., label='Epoch {}'.format(batch+1))\n",
    "    plt.hist(diffs, bins, alpha=0.3, label='Epoch {}'.format(batch+1))\n",
    "    plt.title(\"Histogram of errors in percentage growth\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(file_pre+'.histogram'+file_ext+'.b'+str(batch)+'.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot measured vs. predicted values\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.grid('on')\n",
    "    ax.scatter(y_true, y_pred, color='red', s=10)\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.savefig(file_pre+'.diff'+file_ext+'.b'+str(batch)+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb4eb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLossHistory(Callback):\n",
    "    def __init__(self, progbar, val_gen, test_gen, val_steps, test_steps, metric, category_cutoffs=[0.], ext='', pre='save'):\n",
    "        super(MyLossHistory, self).__init__()\n",
    "        self.progbar = progbar\n",
    "        self.val_gen = val_gen\n",
    "        self.test_gen = test_gen\n",
    "        self.val_steps = val_steps\n",
    "        self.test_steps = test_steps\n",
    "        self.metric = metric\n",
    "        self.category_cutoffs = category_cutoffs\n",
    "        self.pre = pre\n",
    "        self.ext = ext\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.best_val_loss = np.Inf\n",
    "        self.best_val_acc = -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        val_loss, val_acc, y_true, y_pred, y_true_class, y_pred_class = evaluate_model(self.model, self.val_gen, self.val_steps, self.metric, self.category_cutoffs)\n",
    "        test_loss, test_acc, _, _, _, _ = evaluate_model(self.model, self.test_gen, self.test_steps, self.metric, self.category_cutoffs)\n",
    "        self.progbar.append_extra_log_values([('val_acc', val_acc), ('test_loss', test_loss), ('test_acc', test_acc)])\n",
    "        if float(logs.get('val_loss', 0)) < self.best_val_loss:\n",
    "            plot_error(y_true, y_pred, batch, self.ext, self.pre)\n",
    "        self.best_val_loss = min(float(logs.get('val_loss', 0)), self.best_val_loss)\n",
    "        self.best_val_acc = max(float(logs.get('val_acc', 0)), self.best_val_acc)\n",
    "        \n",
    "        \n",
    "    #def on_train_end(self, logs={}):\n",
    "     #   training_stats[tmp_params] = tmp_stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43b1a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProgbarLogger(ProgbarLogger):\n",
    "    def __init__(self, samples):\n",
    "        super(MyProgbarLogger, self).__init__(count_mode='samples')\n",
    "        self.samples = samples\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        super(MyProgbarLogger, self).on_train_begin(logs)\n",
    "        self.verbose = 1\n",
    "        self.extra_log_values = []\n",
    "        self.params['samples'] = self.samples\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if self.seen < self.target:\n",
    "            self.log_values = []\n",
    "            self.extra_log_values = []\n",
    "\n",
    "    def append_extra_log_values(self, tuples):\n",
    "        for k, v in tuples:\n",
    "            self.extra_log_values.append((k, v))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        epoch_log = 'Epoch {}/{}'.format(epoch + 1, self.epochs)\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.log_values.append((k, logs[k]))\n",
    "                epoch_log += ' - {}: {:.4f}'.format(k, logs[k])\n",
    "        for k, v in self.extra_log_values:\n",
    "            self.log_values.append((k, v))\n",
    "            epoch_log += ' - {}: {:.4f}'.format(k, float(v))\n",
    "        if self.verbose:\n",
    "            self.progbar.update(self.seen, self.log_values)\n",
    "        benchmark.logger.debug(epoch_log)\n",
    "        \n",
    "        tmp_stats = epoch_log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0903458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conv_layer(model, layer_params, input_dim=None, locally_connected=False):\n",
    "    if len(layer_params) == 3: # 1D convolution\n",
    "        filters = layer_params[0]\n",
    "        filter_len = layer_params[1]\n",
    "        stride = layer_params[2]\n",
    "        if locally_connected:\n",
    "            if input_dim:\n",
    "                model.add(LocallyConnected1D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(LocallyConnected1D(filters, filter_len, strides=stride))\n",
    "        else:\n",
    "            if input_dim:\n",
    "                model.add(Conv1D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(Conv1D(filters, filter_len, strides=stride))\n",
    "    elif len(layer_params) == 5: # 2D convolution\n",
    "        filters = layer_params[0]\n",
    "        filter_len = (layer_params[1], layer_params[2])\n",
    "        stride = (layer_params[3], layer_params[4])\n",
    "        if locally_connected:\n",
    "            if input_dim:\n",
    "                model.add(LocallyConnected2D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(LocallyConnected2D(filters, filter_len, strides=stride))\n",
    "        else:\n",
    "            if input_dim:\n",
    "                model.add(Conv2D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(Conv2D(filters, filter_len, strides=stride))\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3473db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:\n",
      "{'activation': 'relu',\n",
      " 'batch_normalization': False,\n",
      " 'batch_size': 100,\n",
      " 'category_cutoffs': [0.0],\n",
      " 'cell_features': ['expression'],\n",
      " 'cell_noise_sigma': 0.0,\n",
      " 'data_type': <class 'numpy.float32'>,\n",
      " 'dense': [1000, 500, 100, 50],\n",
      " 'dropout': 0.1,\n",
      " 'drug_features': ['descriptors'],\n",
      " 'epochs': 1,\n",
      " 'experiment_id': 'EXP000',\n",
      " 'feature_subsample': 0,\n",
      " 'initialization': 'normal',\n",
      " 'learning_rate': 0.001,\n",
      " 'logfile': None,\n",
      " 'loss': 'mse',\n",
      " 'max_logconc': -4.0,\n",
      " 'min_logconc': -5.0,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000',\n",
      " 'profiling': False,\n",
      " 'rng_seed': 2017,\n",
      " 'run_id': 'RUN000',\n",
      " 'scaling': 'std',\n",
      " 'scramble': False,\n",
      " 'shuffle': False,\n",
      " 'subsample': 'naive_balancing',\n",
      " 'test_cell_split': 0.15,\n",
      " 'timeout': -1,\n",
      " 'train_bool': True,\n",
      " 'val_split': 0.1,\n",
      " 'verbose': None,\n",
      " 'workers': 1}\n"
     ]
    }
   ],
   "source": [
    "gParameters = initialize_parameters()\n",
    "#gParameters['cell_features'] = 'all'\n",
    "#gParameters['drug_features'] = 'all'\n",
    "benchmark.check_params(gParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7206c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpo(learning_rate, batch_size, epochs, dropout, activation, loss_measure, optimizer, folds):\n",
    "    \n",
    "    gParameters['learning_rate'] = learning_rate\n",
    "    gParameters['batch_size'] = batch_size\n",
    "    gParameters['epochs'] = epochs\n",
    "    gParameters['dropout'] = dropout\n",
    "    gParameters['activation'] = activation\n",
    "    gParameters['optimizer'] = optimizer\n",
    "    \"\"\"\n",
    "    Runs the model using the specified set of parameters\n",
    "\n",
    "    Args:\n",
    "       gParameters: a python dictionary containing the parameters (e.g. epoch)\n",
    "       to run the model with.\n",
    "    \"\"\"\n",
    "    #\n",
    "    if 'dense' in gParameters:\n",
    "        dval = gParameters['dense']\n",
    "        if type(dval) != list:\n",
    "            res = list(dval)\n",
    "        #try:\n",
    "            #is_str = isinstance(dval, basestring)\n",
    "        #except NameError:\n",
    "            #is_str = isinstance(dval, str)\n",
    "        #if is_str:\n",
    "            #res = str2lst(dval)\n",
    "            gParameters['dense'] = res\n",
    "        print(gParameters['dense'])\n",
    "\n",
    "    if 'conv' in gParameters:\n",
    "        flat = gParameters['conv']\n",
    "        gParameters['conv'] = [flat[i:i+3] for i in range(0, len(flat), 3)]\n",
    "        #conv_list = p1_common.parse_conv_list(gParameters['conv'])\n",
    "        #cval = gParameters['conv']\n",
    "        #try:\n",
    "        #    is_str = isinstance(cval, basestring)\n",
    "        #except NameError:\n",
    "        #    is_str = isinstance(cval, str)\n",
    "        #if is_str:\n",
    "        #    res = str2lst(cval)\n",
    "        #    gParameters['conv'] = res\n",
    "        print('Conv input', gParameters['conv'])\n",
    "    # print('Params:', gParameters)\n",
    "    # Construct extension to save model\n",
    "    ext = benchmark.extension_from_parameters(gParameters, '.keras')\n",
    "    logfile = gParameters['logfile'] if gParameters['logfile'] else gParameters['output_dir']+ext+'.log'\n",
    "\n",
    "    fh = logging.FileHandler(logfile)\n",
    "    fh.setFormatter(logging.Formatter(\"[%(asctime)s %(process)d] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"))\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(logging.Formatter(''))\n",
    "    sh.setLevel(logging.DEBUG if gParameters['verbose'] else logging.INFO)\n",
    "\n",
    "    benchmark.logger.setLevel(logging.DEBUG)\n",
    "    benchmark.logger.addHandler(fh)\n",
    "    benchmark.logger.addHandler(sh)\n",
    "    benchmark.logger.info('Params: {}'.format(gParameters))\n",
    "\n",
    "    # Get default parameters for initialization and optimizer functions\n",
    "    kerasDefaults = candle.keras_default_config()\n",
    "    seed = gParameters['rng_seed']\n",
    "\n",
    "    # Build dataset loader object\n",
    "    loader = benchmark.DataLoader(seed=seed, dtype=gParameters['data_type'],\n",
    "                             val_split=gParameters['val_split'],\n",
    "                             test_cell_split=gParameters['test_cell_split'],\n",
    "                             cell_features=gParameters['cell_features'],\n",
    "                             drug_features=gParameters['drug_features'],\n",
    "                             feature_subsample=gParameters['feature_subsample'],\n",
    "                             scaling=gParameters['scaling'],\n",
    "                             scramble=gParameters['scramble'],\n",
    "                             min_logconc=gParameters['min_logconc'],\n",
    "                             max_logconc=gParameters['max_logconc'],\n",
    "                             subsample=gParameters['subsample'],\n",
    "                             category_cutoffs=gParameters['category_cutoffs'])\n",
    "\n",
    "    # Initialize weights and learning rule\n",
    "    initializer_weights = candle.build_initializer(gParameters['initialization'], kerasDefaults, seed)\n",
    "    initializer_bias = candle.build_initializer('constant', kerasDefaults, 0.)\n",
    "\n",
    "    activation = gParameters['activation']\n",
    "\n",
    "    # Define model architecture\n",
    "    gen_shape = None\n",
    "    out_dim = 1\n",
    "\n",
    "    model = Sequential()\n",
    "    if 'dense' in gParameters: # Build dense layers\n",
    "        for layer in gParameters['dense']:\n",
    "            if layer:\n",
    "                model.add(Dense(layer, input_dim=loader.input_dim,\n",
    "                            kernel_initializer=initializer_weights,\n",
    "                            bias_initializer=initializer_bias))\n",
    "                if gParameters['batch_normalization']:\n",
    "                    model.add(BatchNormalization())\n",
    "                model.add(Activation(gParameters['activation']))\n",
    "                if gParameters['dropout']:\n",
    "                    model.add(Dropout(gParameters['dropout']))\n",
    "    else: # Build convolutional layers\n",
    "        gen_shape = 'add_1d'\n",
    "        layer_list = list(range(0, len(gParameters['conv'])))\n",
    "        lc_flag=False\n",
    "        if 'locally_connected' in gParameters:\n",
    "            lc_flag = True\n",
    "\n",
    "        for l, i in enumerate(layer_list):\n",
    "            if i == 0:\n",
    "                add_conv_layer(model, gParameters['conv'][i], input_dim=loader.input_dim,locally_connected=lc_flag)\n",
    "            else:\n",
    "                add_conv_layer(model, gParameters['conv'][i],locally_connected=lc_flag)\n",
    "            if gParameters['batch_normalization']:\n",
    "                    model.add(BatchNormalization())\n",
    "            model.add(Activation(gParameters['activation']))\n",
    "            if gParameters['pool']:\n",
    "                model.add(MaxPooling1D(pool_size=gParameters['pool']))\n",
    "        model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(out_dim))\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = candle.build_optimizer(gParameters['optimizer'],\n",
    "                                                gParameters['learning_rate'],\n",
    "                                                kerasDefaults)\n",
    "    \n",
    "    \n",
    "    # Compile and display model\n",
    "    model.compile(loss=gParameters['loss'], optimizer=optimizer)\n",
    "    model.summary()\n",
    "    benchmark.logger.debug('Model: {}'.format(model.to_json()))\n",
    "\n",
    "    train_gen = benchmark.DataGenerator(loader, batch_size=gParameters['batch_size'], shape=gen_shape, name='train_gen', cell_noise_sigma=gParameters['cell_noise_sigma']).flow()\n",
    "    val_gen = benchmark.DataGenerator(loader, partition='val', batch_size=gParameters['batch_size'], shape=gen_shape, name='val_gen').flow()\n",
    "    val_gen2 = benchmark.DataGenerator(loader, partition='val', batch_size=gParameters['batch_size'], shape=gen_shape, name='val_gen2').flow()\n",
    "    test_gen = benchmark.DataGenerator(loader, partition='test', batch_size=gParameters['batch_size'], shape=gen_shape, name='test_gen').flow()\n",
    "\n",
    "    train_steps = int(loader.n_train/gParameters['batch_size'])\n",
    "    val_steps = int(loader.n_val/gParameters['batch_size'])\n",
    "    test_steps = int(loader.n_test/gParameters['batch_size'])\n",
    "\n",
    "    if 'train_steps' in gParameters:\n",
    "        train_steps = gParameters['train_steps']\n",
    "    if 'val_steps' in gParameters:\n",
    "        val_steps = gParameters['val_steps']\n",
    "    if 'test_steps' in gParameters:\n",
    "        test_steps = gParameters['test_steps']\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=gParameters['output_dir']+'.model'+ext+'.h5', save_best_only=True)\n",
    "    progbar = MyProgbarLogger(train_steps * gParameters['batch_size'])\n",
    "    loss_history = MyLossHistory(progbar=progbar, val_gen=val_gen2, test_gen=test_gen,\n",
    "                            val_steps=val_steps, test_steps=test_steps,\n",
    "                            metric=gParameters['loss'], category_cutoffs=gParameters['category_cutoffs'],\n",
    "                            ext=ext, pre=gParameters['output_dir'])\n",
    "    \n",
    "    # Seed random generator for training\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    candleRemoteMonitor = candle.CandleRemoteMonitor(params=gParameters)\n",
    "\n",
    "    history = model.fit_generator(train_gen, train_steps,\n",
    "                        epochs=gParameters['epochs'],\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=val_steps,\n",
    "                        verbose=0,\n",
    "                        callbacks=[checkpointer, loss_history, progbar, candleRemoteMonitor],\n",
    "                        )\n",
    "\n",
    "    \n",
    "    \n",
    "    benchmark.logger.removeHandler(fh)\n",
    "    benchmark.logger.removeHandler(sh)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c119a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01]\n",
    "batch_sizes = [100, 50]\n",
    "epochs = [5]\n",
    "dropouts = [0.1, 0.6]\n",
    "activations = ['relu']\n",
    "optimizers = ['adam', 'sgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a493374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 500, 100, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3.py:533: ParserWarning: Both a converter and dtype were specified for column NAME - only the converter will be used\n",
      "  converters ={'NAME' : str})\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 1000)              23062000  \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 23,617,701\n",
      "Trainable params: 23,617,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "231200/231200 [==============================] - 317s 1ms/step - loss: 0.0363 - val_loss: 1.1046e-04 - val_acc: 0.5293 - test_loss: 9.8626e-05 - test_acc: 0.5046\n",
      "Epoch 2/5\n",
      "231200/231200 [==============================] - 304s 1ms/step - loss: 1.2373e-04 - val_loss: 9.3481e-05 - val_acc: 0.5234 - test_loss: 9.9109e-05 - test_acc: 0.5126\n",
      "Epoch 3/5\n",
      "231200/231200 [==============================] - 305s 1ms/step - loss: 1.0230e-04 - val_loss: 1.2719e-04 - val_acc: 0.5205 - test_loss: 9.9301e-05 - test_acc: 0.5096\n",
      "Epoch 4/5\n",
      "231200/231200 [==============================] - 307s 1ms/step - loss: 1.0341e-04 - val_loss: 1.3432e-04 - val_acc: 0.5787 - test_loss: 9.4899e-05 - test_acc: 0.5728\n",
      "Epoch 5/5\n",
      "231200/231200 [==============================] - 309s 1ms/step - loss: 4.6641e-04 - val_loss: 1.1147e-04 - val_acc: 0.5217 - test_loss: 9.8934e-05 - test_acc: 0.5133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.6, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 500, 100, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3.py:533: ParserWarning: Both a converter and dtype were specified for column NAME - only the converter will be used\n",
      "  converters ={'NAME' : str})\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 1000)              23062000  \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 23,617,701\n",
      "Trainable params: 23,617,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "231200/231200 [==============================] - 312s 1ms/step - loss: 1.2472 - val_loss: 1.1323e-04 - val_acc: 0.4784 - test_loss: 9.8636e-05 - test_acc: 0.4867\n",
      "Epoch 2/5\n",
      "231200/231200 [==============================] - 304s 1ms/step - loss: 0.0036 - val_loss: 9.3592e-05 - val_acc: 0.5213 - test_loss: 9.9028e-05 - test_acc: 0.5126\n",
      "Epoch 3/5\n",
      "231200/231200 [==============================] - 305s 1ms/step - loss: 0.0029 - val_loss: 1.2416e-04 - val_acc: 0.4786 - test_loss: 9.8547e-05 - test_acc: 0.4872\n",
      "Epoch 4/5\n",
      "231200/231200 [==============================] - 306s 1ms/step - loss: 0.0080 - val_loss: 1.4437e-04 - val_acc: 0.5216 - test_loss: 9.8519e-05 - test_acc: 0.5126\n",
      "Epoch 5/5\n",
      "231200/231200 [==============================] - 305s 1ms/step - loss: 5.8136e-04 - val_loss: 1.1105e-04 - val_acc: 0.5217 - test_loss: 9.8711e-05 - test_acc: 0.5133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 50, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adam', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Loaded 451169 unique (D, CL) response sets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 500, 100, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "Loaded 451169 unique (D, CL) response sets.\n",
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3.py:533: ParserWarning: Both a converter and dtype were specified for column NAME - only the converter will be used\n",
      "  converters ={'NAME' : str})\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "Distribution of dose response:\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Category cutoffs: [0.0]\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "Dose response bin counts:\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "  Total:    261576\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "Input features shapes:\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  drug_concentration: (1,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  cell_expression: (19221,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "  drug_descriptors: (3839,)\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n",
      "Total input dimensions: 23061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 1000)              23062000  \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 23,617,701\n",
      "Trainable params: 23,617,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "231200/231200 [==============================] - 545s 2ms/step - loss: 0.0166 - val_loss: 8.9868e-05 - val_acc: 0.5214 - test_loss: 9.9016e-05 - test_acc: 0.5133\n",
      "Epoch 2/5\n",
      "231200/231200 [==============================] - 542s 2ms/step - loss: 1.0337e-04 - val_loss: 1.0018e-04 - val_acc: 0.5216 - test_loss: 1.0019e-04 - test_acc: 0.5126\n",
      "Epoch 3/5\n",
      "109250/231200 [=============>................] - ETA: 3:48 - loss: 1.0487e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-12d56ba7cfa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mtmp_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                         hpo(learning_rate, batch_size, epoch, dropout, activation, loss_measure=None,\n\u001b[0;32m---> 18\u001b[0;31m                             optimizer=optimizer, folds=None)\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0mtmp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stats'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mtraining_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-201af45dd1cb>\u001b[0m in \u001b[0;36mhpo\u001b[0;34m(learning_rate, batch_size, epochs, dropout, activation, loss_measure, optimizer, folds)\u001b[0m\n\u001b[1;32m    164\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandleRemoteMonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                         )\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for optimizer in optimizers:\n",
    "        for batch_size in batch_sizes:\n",
    "            for dropout in dropouts:\n",
    "                for activation in activations:\n",
    "                    for epoch in epochs:\n",
    "                        tmp_dict = {}\n",
    "                        tmp_dict['Params'] = ['Learning Rate: {}'.format(learning_rate),\n",
    "                                                           'Optimizer: {}'.format(optimizer),\n",
    "                                                           'Batch Size: {}'.format(batch_size),\n",
    "                                                           'Epochs: {}'.format(epoch),\n",
    "                                                           'Dropout: {}'.format(dropout), \n",
    "                                                           'Activation: {}'.format(activation)]\n",
    "                        tmp_stats = ''\n",
    "                        hpo(learning_rate, batch_size, epoch, dropout, activation, loss_measure=None,\n",
    "                            optimizer=optimizer, folds=None)\n",
    "                        tmp_dict['stats'] = tmp_stats\n",
    "                        training_stats[count] = tmp_dict\n",
    "                        count += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96cacbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e76fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "with open(\"hpo_run_\" + str(now) + \".json\", \"w\") as outfile:\n",
    "    json.dump(training_stats, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a6b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f97d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39d13568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a04b1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93473f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ebd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564bf851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbab010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff3b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d374ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe23a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = benchmark.DataGenerator(loader, partition='test', batch_size=gParameters['batch_size'], shape=gen_shape, name='test_gen').flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c878cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = int(loader.n_test/gParameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5d3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test_steps' in gParameters:\n",
    "    test_steps = gParameters['test_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5448772",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.logger.info('test_loss: {:.4f}'.format(test_loss))\n",
    "benchmark.logger.info('test_acc: {:.4f}'.format(test_acc))\n",
    "benchmark.logger.removeHandler(fh)\n",
    "benchmark.logger.removeHandler(sh)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b96ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7977c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import p1b3 as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf91340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_expr_path, cell_mrna_path, cell_prot_path, cell_kino_path,drug_desc_path, drug_auen_path, dose_resp_path, test_cell_path, test_drug_path = benchmark.stage_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6727c2cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e2067d612c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dose_response_gdsc = benchmark.load_dose_response(dose_resp_path, seed, gParameters['data_type'],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 min_logconc=gParameters['min_logconc'], max_logconc=gParameters['max_logconc'], subsample=gParameters['subsample'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "dose_response_gdsc = benchmark.load_dose_response(dose_resp_path, seed, gParameters['data_type'],\n",
    "                                min_logconc=gParameters['min_logconc'], max_logconc=gParameters['max_logconc'], subsample=gParameters['subsample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "308c499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELLNAME</th>\n",
       "      <th>GROWTH</th>\n",
       "      <th>LOG_CONCENTRATION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDSC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>0.701901</td>\n",
       "      <td>4.834112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>0.705002</td>\n",
       "      <td>3.350517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>-1.656763</td>\n",
       "      <td>1.199252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>-1.655299</td>\n",
       "      <td>0.831239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000006</td>\n",
       "      <td>-0.318435</td>\n",
       "      <td>3.261706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CELLNAME    GROWTH  LOG_CONCENTRATION\n",
       "GDSC                                         \n",
       "1     ACH-000002  0.701901           4.834112\n",
       "1     ACH-000002  0.705002           3.350517\n",
       "1     ACH-000004 -1.656763           1.199252\n",
       "1     ACH-000004 -1.655299           0.831239\n",
       "1     ACH-000006 -0.318435           3.261706"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dose_response_gdsc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d191af1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f94fbe260d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_cell_expr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "loader.df_cell_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ecef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1b3",
   "language": "python",
   "name": "p1b3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

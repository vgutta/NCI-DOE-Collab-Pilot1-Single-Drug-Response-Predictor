{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98405f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing candle utils for keras\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.backend.tensorflow_backend import set_session\\nimport tensorflow as tf\\nconfig = tf.ConfigProto()\\nconfig.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\\nconfig.log_device_placement = True  # to log device placement (on which device the operation ran)\\nsess = tf.Session(config=config)\\nset_session(sess)  # set this TensorFlow session as the default session for Keras\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Multilayer Perceptron for drug response problem\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, LocallyConnected1D, Conv1D, MaxPooling1D, Flatten, Conv2D, LocallyConnected2D\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ProgbarLogger\n",
    "\n",
    "# For non-interactive plotting\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import p1b3 as benchmark\n",
    "import candle\n",
    "\n",
    "sys.argv = [''] # for Jupyter nbs\n",
    "\n",
    "#cfg = K.tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "#K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    "'''\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2593da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(default_model = 'p1b3_default_model.txt'):\n",
    "    \n",
    "    # Build benchmark object\n",
    "    p1b3Bmk = benchmark.BenchmarkP1B3(benchmark.file_path, default_model, 'keras',\n",
    "    prog='p1b3_baseline', desc='Multi-task (DNN) for data extraction from clinical reports - Pilot 3 Benchmark 1')\n",
    "    \n",
    "    \n",
    "    # Initialize parameters\n",
    "    gParameters = candle.finalize_parameters(p1b3Bmk)\n",
    "    #benchmark.logger.info('Params: {}'.format(gParameters))\n",
    "\n",
    "    return gParameters\n",
    "\n",
    "def str2lst(string_val):\n",
    "    result = [int(x) for x in string_val.split(' ')]\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate_keras_metric(y_true, y_pred, metric):\n",
    "    objective_function = metrics.get(metric)\n",
    "    objective = objective_function(y_true, y_pred)\n",
    "    return K.eval(objective)\n",
    "\n",
    "\n",
    "def evaluate_model(model, generator, steps, metric, category_cutoffs=[0.]):\n",
    "    y_true, y_pred = None, None\n",
    "    count = 0\n",
    "    while count < steps:\n",
    "        x_batch, y_batch = next(generator)\n",
    "        y_batch_pred = model.predict_on_batch(x_batch)\n",
    "        y_batch_pred = y_batch_pred.ravel()\n",
    "        y_true = np.concatenate((y_true, y_batch)) if y_true is not None else y_batch\n",
    "        y_pred = np.concatenate((y_pred, y_batch_pred)) if y_pred is not None else y_batch_pred\n",
    "        count += 1\n",
    "\n",
    "    loss = evaluate_keras_metric(y_true.astype(np.float32), y_pred.astype(np.float32), metric)\n",
    "\n",
    "    y_true_class = np.digitize(y_true, category_cutoffs)\n",
    "    y_pred_class = np.digitize(y_pred, category_cutoffs)\n",
    "\n",
    "    # theano does not like integer input\n",
    "    acc = evaluate_keras_metric(y_true_class.astype(np.float32), y_pred_class.astype(np.float32), 'binary_accuracy')  # works for multiclass labels as well\n",
    "\n",
    "    return loss, acc, y_true, y_pred, y_true_class, y_pred_class\n",
    "\n",
    "\n",
    "def plot_error(y_true, y_pred, batch, file_ext, file_pre='output_dir', subsample=1000):\n",
    "    if batch % 10:\n",
    "        return\n",
    "\n",
    "    total = len(y_true)\n",
    "    if subsample and subsample < total:\n",
    "        usecols = np.random.choice(total, size=subsample, replace=False)\n",
    "        y_true = y_true[usecols]\n",
    "        y_pred = y_pred[usecols]\n",
    "\n",
    "    y_true = y_true * 100\n",
    "    y_pred = y_pred * 100\n",
    "    diffs = y_pred - y_true\n",
    "\n",
    "    bins = np.linspace(-200, 200, 100)\n",
    "    if batch == 0:\n",
    "        y_shuf = np.random.permutation(y_true)\n",
    "        plt.hist(y_shuf - y_true, bins, alpha=0.5, label='Random')\n",
    "\n",
    "    #plt.hist(diffs, bins, alpha=0.35-batch/100., label='Epoch {}'.format(batch+1))\n",
    "    plt.hist(diffs, bins, alpha=0.3, label='Epoch {}'.format(batch+1))\n",
    "    plt.title(\"Histogram of errors in percentage growth\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(file_pre+'.histogram'+file_ext+'.b'+str(batch)+'.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot measured vs. predicted values\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.grid('on')\n",
    "    ax.scatter(y_true, y_pred, color='red', s=10)\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.savefig(file_pre+'.diff'+file_ext+'.b'+str(batch)+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da32a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLossHistory(Callback):\n",
    "    def __init__(self, progbar, val_gen, test_gen, val_steps, test_steps, metric, category_cutoffs=[0.], ext='', pre='save'):\n",
    "        super(MyLossHistory, self).__init__()\n",
    "        self.progbar = progbar\n",
    "        self.val_gen = val_gen\n",
    "        self.test_gen = test_gen\n",
    "        self.val_steps = val_steps\n",
    "        self.test_steps = test_steps\n",
    "        self.metric = metric\n",
    "        self.category_cutoffs = category_cutoffs\n",
    "        self.pre = pre\n",
    "        self.ext = ext\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.best_val_loss = np.Inf\n",
    "        self.best_val_acc = -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        val_loss, val_acc, y_true, y_pred, y_true_class, y_pred_class = evaluate_model(self.model, self.val_gen, self.val_steps, self.metric, self.category_cutoffs)\n",
    "        test_loss, test_acc, _, _, _, _ = evaluate_model(self.model, self.test_gen, self.test_steps, self.metric, self.category_cutoffs)\n",
    "        self.progbar.append_extra_log_values([('val_acc', val_acc), ('test_loss', test_loss), ('test_acc', test_acc)])\n",
    "        if float(logs.get('val_loss', 0)) < self.best_val_loss:\n",
    "            plot_error(y_true, y_pred, batch, self.ext, self.pre)\n",
    "        self.best_val_loss = min(float(logs.get('val_loss', 0)), self.best_val_loss)\n",
    "        self.best_val_acc = max(float(logs.get('val_acc', 0)), self.best_val_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2240dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProgbarLogger(ProgbarLogger):\n",
    "    def __init__(self, samples):\n",
    "        super(MyProgbarLogger, self).__init__(count_mode='samples')\n",
    "        self.samples = samples\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        super(MyProgbarLogger, self).on_train_begin(logs)\n",
    "        self.verbose = 1\n",
    "        self.extra_log_values = []\n",
    "        self.params['samples'] = self.samples\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if self.seen < self.target:\n",
    "            self.log_values = []\n",
    "            self.extra_log_values = []\n",
    "\n",
    "    def append_extra_log_values(self, tuples):\n",
    "        for k, v in tuples:\n",
    "            self.extra_log_values.append((k, v))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        epoch_log = 'Epoch {}/{}'.format(epoch + 1, self.epochs)\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.log_values.append((k, logs[k]))\n",
    "                epoch_log += ' - {}: {:.4f}'.format(k, logs[k])\n",
    "        for k, v in self.extra_log_values:\n",
    "            self.log_values.append((k, v))\n",
    "            epoch_log += ' - {}: {:.4f}'.format(k, float(v))\n",
    "        if self.verbose:\n",
    "            self.progbar.update(self.seen, self.log_values)\n",
    "        benchmark.logger.debug(epoch_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220c9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conv_layer(model, layer_params, input_dim=None, locally_connected=False):\n",
    "    if len(layer_params) == 3: # 1D convolution\n",
    "        filters = layer_params[0]\n",
    "        filter_len = layer_params[1]\n",
    "        stride = layer_params[2]\n",
    "        if locally_connected:\n",
    "            if input_dim:\n",
    "                model.add(LocallyConnected1D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(LocallyConnected1D(filters, filter_len, strides=stride))\n",
    "        else:\n",
    "            if input_dim:\n",
    "                model.add(Conv1D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(Conv1D(filters, filter_len, strides=stride))\n",
    "    elif len(layer_params) == 5: # 2D convolution\n",
    "        filters = layer_params[0]\n",
    "        filter_len = (layer_params[1], layer_params[2])\n",
    "        stride = (layer_params[3], layer_params[4])\n",
    "        if locally_connected:\n",
    "            if input_dim:\n",
    "                model.add(LocallyConnected2D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(LocallyConnected2D(filters, filter_len, strides=stride))\n",
    "        else:\n",
    "            if input_dim:\n",
    "                model.add(Conv2D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(Conv2D(filters, filter_len, strides=stride))\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4ee378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:\n",
      "{'activation': 'relu',\n",
      " 'batch_normalization': False,\n",
      " 'batch_size': 100,\n",
      " 'category_cutoffs': [0.0],\n",
      " 'cell_features': ['expression'],\n",
      " 'cell_noise_sigma': 0.0,\n",
      " 'data_type': <class 'numpy.float32'>,\n",
      " 'dense': [1000, 500, 100, 50],\n",
      " 'dropout': 0.1,\n",
      " 'drug_features': ['descriptors'],\n",
      " 'epochs': 1,\n",
      " 'experiment_id': 'EXP000',\n",
      " 'feature_subsample': 0,\n",
      " 'initialization': 'normal',\n",
      " 'learning_rate': 0.001,\n",
      " 'logfile': None,\n",
      " 'loss': 'mse',\n",
      " 'max_logconc': -4.0,\n",
      " 'min_logconc': -5.0,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000',\n",
      " 'profiling': False,\n",
      " 'rng_seed': 2017,\n",
      " 'run_id': 'RUN000',\n",
      " 'scaling': 'std',\n",
      " 'scramble': False,\n",
      " 'shuffle': False,\n",
      " 'subsample': 'naive_balancing',\n",
      " 'test_cell_split': 0.15,\n",
      " 'timeout': -1,\n",
      " 'train_bool': True,\n",
      " 'val_split': 0.1,\n",
      " 'verbose': None,\n",
      " 'workers': 1}\n"
     ]
    }
   ],
   "source": [
    "gParameters = initialize_parameters()\n",
    "gParameters['cell_features'] = 'all'\n",
    "gParameters['drug_features'] = 'all'\n",
    "benchmark.check_params(gParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0868e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 1, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'sgd', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': 'all', 'drug_features': 'all', 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1}\n",
      "Loaded 451169 unique (D, CL) response sets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 500, 100, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3.py:533: ParserWarning: Both a converter and dtype were specified for column NAME - only the converter will be used\n",
      "  converters ={'NAME' : str})\n",
      "Distribution of dose response:\n",
      "              GROWTH\n",
      "count  261576.000000\n",
      "mean        0.020341\n",
      "std         1.002191\n",
      "min       -10.276382\n",
      "25%        -0.612788\n",
      "50%         0.047490\n",
      "75%         0.684798\n",
      "max         5.276222\n",
      "Category cutoffs: [0.0]\n",
      "Dose response bin counts:\n",
      "  Class 0:  125650 (0.4804) - between -0.10 and +0.00\n",
      "  Class 1:  135926 (0.5196) - between +0.00 and +0.05\n",
      "  Total:    261576\n",
      "Rows in train: 231248, val: 25694, test: 4634\n",
      "Input features shapes:\n",
      "  drug_concentration: (1,)\n",
      "  cell_expression: (19221,)\n",
      "  drug_descriptors: (3839,)\n",
      "Total input dimensions: 23061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs the model using the specified set of parameters\n",
    "\n",
    "Args:\n",
    "   gParameters: a python dictionary containing the parameters (e.g. epoch)\n",
    "   to run the model with.\n",
    "\"\"\"\n",
    "#\n",
    "if 'dense' in gParameters:\n",
    "    dval = gParameters['dense']\n",
    "    if type(dval) != list:\n",
    "        res = list(dval)\n",
    "    #try:\n",
    "        #is_str = isinstance(dval, basestring)\n",
    "    #except NameError:\n",
    "        #is_str = isinstance(dval, str)\n",
    "    #if is_str:\n",
    "        #res = str2lst(dval)\n",
    "        gParameters['dense'] = res\n",
    "    print(gParameters['dense'])\n",
    "\n",
    "if 'conv' in gParameters:\n",
    "    flat = gParameters['conv']\n",
    "    gParameters['conv'] = [flat[i:i+3] for i in range(0, len(flat), 3)]\n",
    "    #conv_list = p1_common.parse_conv_list(gParameters['conv'])\n",
    "    #cval = gParameters['conv']\n",
    "    #try:\n",
    "    #    is_str = isinstance(cval, basestring)\n",
    "    #except NameError:\n",
    "    #    is_str = isinstance(cval, str)\n",
    "    #if is_str:\n",
    "    #    res = str2lst(cval)\n",
    "    #    gParameters['conv'] = res\n",
    "    print('Conv input', gParameters['conv'])\n",
    "# print('Params:', gParameters)\n",
    "# Construct extension to save model\n",
    "ext = benchmark.extension_from_parameters(gParameters, '.keras')\n",
    "logfile = gParameters['logfile'] if gParameters['logfile'] else gParameters['output_dir']+ext+'.log'\n",
    "\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setFormatter(logging.Formatter(\"[%(asctime)s %(process)d] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"))\n",
    "fh.setLevel(logging.DEBUG)\n",
    "\n",
    "sh = logging.StreamHandler()\n",
    "sh.setFormatter(logging.Formatter(''))\n",
    "sh.setLevel(logging.DEBUG if gParameters['verbose'] else logging.INFO)\n",
    "\n",
    "benchmark.logger.setLevel(logging.DEBUG)\n",
    "benchmark.logger.addHandler(fh)\n",
    "benchmark.logger.addHandler(sh)\n",
    "benchmark.logger.info('Params: {}'.format(gParameters))\n",
    "\n",
    "# Get default parameters for initialization and optimizer functions\n",
    "kerasDefaults = candle.keras_default_config()\n",
    "seed = gParameters['rng_seed']\n",
    "\n",
    "# Build dataset loader object\n",
    "loader = benchmark.DataLoader(seed=seed, dtype=gParameters['data_type'],\n",
    "                         val_split=gParameters['val_split'],\n",
    "                         test_cell_split=gParameters['test_cell_split'],\n",
    "                         cell_features=gParameters['cell_features'],\n",
    "                         drug_features=gParameters['drug_features'],\n",
    "                         feature_subsample=gParameters['feature_subsample'],\n",
    "                         scaling=gParameters['scaling'],\n",
    "                         scramble=gParameters['scramble'],\n",
    "                         min_logconc=gParameters['min_logconc'],\n",
    "                         max_logconc=gParameters['max_logconc'],\n",
    "                         subsample=gParameters['subsample'],\n",
    "                         category_cutoffs=gParameters['category_cutoffs'])\n",
    "\n",
    "# Initialize weights and learning rule\n",
    "initializer_weights = candle.build_initializer(gParameters['initialization'], kerasDefaults, seed)\n",
    "initializer_bias = candle.build_initializer('constant', kerasDefaults, 0.)\n",
    "\n",
    "activation = gParameters['activation']\n",
    "\n",
    "# Define model architecture\n",
    "gen_shape = None\n",
    "out_dim = 1\n",
    "\n",
    "model = Sequential()\n",
    "if 'dense' in gParameters: # Build dense layers\n",
    "    for layer in gParameters['dense']:\n",
    "        if layer:\n",
    "            model.add(Dense(layer, input_dim=loader.input_dim,\n",
    "                        kernel_initializer=initializer_weights,\n",
    "                        bias_initializer=initializer_bias))\n",
    "            if gParameters['batch_normalization']:\n",
    "                model.add(BatchNormalization())\n",
    "            model.add(Activation(gParameters['activation']))\n",
    "            if gParameters['dropout']:\n",
    "                model.add(Dropout(gParameters['dropout']))\n",
    "else: # Build convolutional layers\n",
    "    gen_shape = 'add_1d'\n",
    "    layer_list = list(range(0, len(gParameters['conv'])))\n",
    "    lc_flag=False\n",
    "    if 'locally_connected' in gParameters:\n",
    "        lc_flag = True\n",
    "\n",
    "    for l, i in enumerate(layer_list):\n",
    "        if i == 0:\n",
    "            add_conv_layer(model, gParameters['conv'][i], input_dim=loader.input_dim,locally_connected=lc_flag)\n",
    "        else:\n",
    "            add_conv_layer(model, gParameters['conv'][i],locally_connected=lc_flag)\n",
    "        if gParameters['batch_normalization']:\n",
    "                model.add(BatchNormalization())\n",
    "        model.add(Activation(gParameters['activation']))\n",
    "        if gParameters['pool']:\n",
    "            model.add(MaxPooling1D(pool_size=gParameters['pool']))\n",
    "    model.add(Flatten())\n",
    "\n",
    "model.add(Dense(out_dim))\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = candle.build_optimizer(gParameters['optimizer'],\n",
    "                                            gParameters['learning_rate'],\n",
    "                                            kerasDefaults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec5c3766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              23062000  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 23,617,701\n",
      "Trainable params: 23,617,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile and display model\n",
    "model.compile(loss=gParameters['loss'], optimizer=optimizer)\n",
    "model.summary()\n",
    "benchmark.logger.debug('Model: {}'.format(model.to_json()))\n",
    "\n",
    "train_gen = benchmark.DataGenerator(loader, batch_size=gParameters['batch_size'], shape=gen_shape, name='train_gen', cell_noise_sigma=gParameters['cell_noise_sigma']).flow()\n",
    "val_gen = benchmark.DataGenerator(loader, partition='val', batch_size=gParameters['batch_size'], shape=gen_shape, name='val_gen').flow()\n",
    "val_gen2 = benchmark.DataGenerator(loader, partition='val', batch_size=gParameters['batch_size'], shape=gen_shape, name='val_gen2').flow()\n",
    "test_gen = benchmark.DataGenerator(loader, partition='test', batch_size=gParameters['batch_size'], shape=gen_shape, name='test_gen').flow()\n",
    "\n",
    "train_steps = int(loader.n_train/gParameters['batch_size'])\n",
    "val_steps = int(loader.n_val/gParameters['batch_size'])\n",
    "test_steps = int(loader.n_test/gParameters['batch_size'])\n",
    "\n",
    "if 'train_steps' in gParameters:\n",
    "    train_steps = gParameters['train_steps']\n",
    "if 'val_steps' in gParameters:\n",
    "    val_steps = gParameters['val_steps']\n",
    "if 'test_steps' in gParameters:\n",
    "    test_steps = gParameters['test_steps']\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=gParameters['output_dir']+'.model'+ext+'.h5', save_best_only=True)\n",
    "progbar = MyProgbarLogger(train_steps * gParameters['batch_size'])\n",
    "loss_history = MyLossHistory(progbar=progbar, val_gen=val_gen2, test_gen=test_gen,\n",
    "                        val_steps=val_steps, test_steps=test_steps,\n",
    "                        metric=gParameters['loss'], category_cutoffs=gParameters['category_cutoffs'],\n",
    "                        ext=ext, pre=gParameters['output_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16be7ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "231200/231200 [==============================] - 329s 1ms/step - loss: 0.0446 - val_loss: 2.4118e-04 - val_acc: 0.4790 - test_loss: 1.8485e-04 - test_acc: 0.4813\n"
     ]
    }
   ],
   "source": [
    "# Seed random generator for training\n",
    "np.random.seed(seed)\n",
    "\n",
    "candleRemoteMonitor = candle.CandleRemoteMonitor(params=gParameters)\n",
    "\n",
    "history = model.fit_generator(train_gen, train_steps,\n",
    "                    epochs=gParameters['epochs'],\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    verbose=0,\n",
    "                    callbacks=[checkpointer, loss_history, progbar, candleRemoteMonitor],\n",
    "                    )\n",
    "\n",
    "benchmark.logger.removeHandler(fh)\n",
    "benchmark.logger.removeHandler(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4789a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249649e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74824808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a38c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b59d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33cf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a53a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb1582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = benchmark.DataGenerator(loader, partition='test', batch_size=gParameters['batch_size'], shape=gen_shape, name='test_gen').flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04362f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = int(loader.n_test/gParameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd723b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test_steps' in gParameters:\n",
    "    test_steps = gParameters['test_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f89d1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (40037,) but got array with shape (23061,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3b1a75ae6486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgParameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_cutoffs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgParameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_cutoffs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-d57dc1879f69>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, generator, steps, metric, category_cutoffs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0my_batch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0my_batch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \"\"\"\n\u001b[0;32m-> 1574\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2216/.conda/envs/p1b3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (40037,) but got array with shape (23061,)"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, _, _, _, _ = evaluate_model(model, test_gen, test_steps, metric=gParameters['loss'], category_cutoffs=gParameters['category_cutoffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.logger.info('test_loss: {:.4f}'.format(test_loss))\n",
    "benchmark.logger.info('test_acc: {:.4f}'.format(test_acc))\n",
    "benchmark.logger.removeHandler(fh)\n",
    "benchmark.logger.removeHandler(sh)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f385121",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc91674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import p1b3 as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d128c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_expr_path, cell_mrna_path, cell_prot_path, cell_kino_path,drug_desc_path, drug_auen_path, dose_resp_path, test_cell_path, test_drug_path = benchmark.stage_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc83ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e2067d612c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dose_response_gdsc = benchmark.load_dose_response(dose_resp_path, seed, gParameters['data_type'],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 min_logconc=gParameters['min_logconc'], max_logconc=gParameters['max_logconc'], subsample=gParameters['subsample'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "dose_response_gdsc = benchmark.load_dose_response(dose_resp_path, seed, gParameters['data_type'],\n",
    "                                min_logconc=gParameters['min_logconc'], max_logconc=gParameters['max_logconc'], subsample=gParameters['subsample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7bf16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELLNAME</th>\n",
       "      <th>GROWTH</th>\n",
       "      <th>LOG_CONCENTRATION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDSC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>0.701901</td>\n",
       "      <td>4.834112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>0.705002</td>\n",
       "      <td>3.350517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>-1.656763</td>\n",
       "      <td>1.199252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>-1.655299</td>\n",
       "      <td>0.831239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000006</td>\n",
       "      <td>-0.318435</td>\n",
       "      <td>3.261706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CELLNAME    GROWTH  LOG_CONCENTRATION\n",
       "GDSC                                         \n",
       "1     ACH-000002  0.701901           4.834112\n",
       "1     ACH-000002  0.705002           3.350517\n",
       "1     ACH-000004 -1.656763           1.199252\n",
       "1     ACH-000004 -1.655299           0.831239\n",
       "1     ACH-000006 -0.318435           3.261706"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dose_response_gdsc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c58db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f94fbe260d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_cell_expr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "loader.df_cell_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059d514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1b3",
   "language": "python",
   "name": "p1b3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

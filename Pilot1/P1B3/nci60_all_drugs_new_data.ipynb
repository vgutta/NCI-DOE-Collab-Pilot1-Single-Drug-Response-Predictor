{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33b3207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing candle utils for keras\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Multilayer Perceptron for drug response problem\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, LocallyConnected1D, Conv1D, MaxPooling1D, Flatten, Conv2D, LocallyConnected2D\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ProgbarLogger\n",
    "\n",
    "# For non-interactive plotting\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#import p1b3 as benchmark\n",
    "import p1b3_all_drugs_new_data as benchmark\n",
    "import candle\n",
    "\n",
    "sys.argv = [''] # for Jupyter nbs\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b46840e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def initialize_parameters(default_model = 'p1b3_default_model.txt'):\n",
    "\n",
    "    # Build benchmark object\n",
    "    p1b3Bmk = benchmark.BenchmarkP1B3(benchmark.file_path, default_model, 'keras',\n",
    "    prog='p1b3_baseline', desc='Multi-task (DNN) for data extraction from clinical reports - Pilot 3 Benchmark 1')\n",
    "    \n",
    "    # Initialize parameters\n",
    "    gParameters = candle.finalize_parameters(p1b3Bmk)\n",
    "    #benchmark.logger.info(a'Params: {}'.format(gParameters))\n",
    "\n",
    "    return gParameters\n",
    "\n",
    "def str2lst(string_val):\n",
    "    result = [int(x) for x in string_val.split(' ')]\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate_keras_metric(y_true, y_pred, metric):\n",
    "    objective_function = metrics.get(metric)\n",
    "    objective = objective_function(y_true, y_pred)\n",
    "    return K.eval(objective)\n",
    "\n",
    "\n",
    "def evaluate_model(model, generator, steps, metric, category_cutoffs=[0.]):\n",
    "    y_true, y_pred = None, None\n",
    "    count = 0\n",
    "    while count < steps:\n",
    "        x_batch, y_batch = next(generator)\n",
    "        y_batch_pred = model.predict_on_batch(x_batch)\n",
    "        y_batch_pred = y_batch_pred.ravel()\n",
    "        y_true = np.concatenate((y_true, y_batch)) if y_true is not None else y_batch\n",
    "        y_pred = np.concatenate((y_pred, y_batch_pred)) if y_pred is not None else y_batch_pred\n",
    "        count += 1\n",
    "\n",
    "    loss = evaluate_keras_metric(y_true.astype(np.float32), y_pred.astype(np.float32), metric)\n",
    "\n",
    "    y_true_class = np.digitize(y_true, category_cutoffs)\n",
    "    y_pred_class = np.digitize(y_pred, category_cutoffs)\n",
    "\n",
    "    # theano does not like integer input\n",
    "    acc = evaluate_keras_metric(y_true_class.astype(np.float32), y_pred_class.astype(np.float32), 'binary_accuracy')  # works for multiclass labels as well\n",
    "\n",
    "    return loss, acc, y_true, y_pred, y_true_class, y_pred_class\n",
    "\n",
    "\n",
    "def plot_error(y_true, y_pred, batch, file_ext, file_pre='output_dir', subsample=1000):\n",
    "    if batch % 10:\n",
    "        return\n",
    "\n",
    "    total = len(y_true)\n",
    "    if subsample and subsample < total:\n",
    "        usecols = np.random.choice(total, size=subsample, replace=False)\n",
    "        y_true = y_true[usecols]\n",
    "        y_pred = y_pred[usecols]\n",
    "\n",
    "    y_true = y_true * 100\n",
    "    y_pred = y_pred * 100\n",
    "    diffs = y_pred - y_true\n",
    "\n",
    "    bins = np.linspace(-200, 200, 100)\n",
    "    if batch == 0:\n",
    "        y_shuf = np.random.permutation(y_true)\n",
    "        plt.hist(y_shuf - y_true, bins, alpha=0.5, label='Random')\n",
    "\n",
    "    #plt.hist(diffs, bins, alpha=0.35-batch/100., label='Epoch {}'.format(batch+1))\n",
    "    plt.hist(diffs, bins, alpha=0.3, label='Epoch {}'.format(batch+1))\n",
    "    plt.title(\"Histogram of errors in percentage growth\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(file_pre+'.histogram'+file_ext+'.b'+str(batch)+'.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot measured vs. predicted values\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.grid('on')\n",
    "    ax.scatter(y_true, y_pred, color='red', s=10)\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.savefig(file_pre+'.diff'+file_ext+'.b'+str(batch)+'.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "class MyLossHistory(Callback):\n",
    "    def __init__(self, progbar, val_gen, test_gen, val_steps, test_steps, metric, category_cutoffs=[0.], ext='', pre='save'):\n",
    "        super(MyLossHistory, self).__init__()\n",
    "        self.progbar = progbar\n",
    "        self.val_gen = val_gen\n",
    "        self.test_gen = test_gen\n",
    "        self.val_steps = val_steps\n",
    "        self.test_steps = test_steps\n",
    "        self.metric = metric\n",
    "        self.category_cutoffs = category_cutoffs\n",
    "        self.pre = pre\n",
    "        self.ext = ext\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.best_val_loss = np.Inf\n",
    "        self.best_val_acc = -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        val_loss, val_acc, y_true, y_pred, y_true_class, y_pred_class = evaluate_model(self.model, self.val_gen, self.val_steps, self.metric, self.category_cutoffs)\n",
    "        test_loss, test_acc, _, _, _, _ = evaluate_model(self.model, self.test_gen, self.test_steps, self.metric, self.category_cutoffs)\n",
    "        self.progbar.append_extra_log_values([('val_acc', val_acc), ('test_loss', test_loss), ('test_acc', test_acc)])\n",
    "        if float(logs.get('val_loss', 0)) < self.best_val_loss:\n",
    "            plot_error(y_true, y_pred, batch, self.ext, self.pre)\n",
    "        self.best_val_loss = min(float(logs.get('val_loss', 0)), self.best_val_loss)\n",
    "        self.best_val_acc = max(float(logs.get('val_acc', 0)), self.best_val_acc)\n",
    "\n",
    "\n",
    "class MyProgbarLogger(ProgbarLogger):\n",
    "    def __init__(self, samples):\n",
    "        super(MyProgbarLogger, self).__init__(count_mode='samples')\n",
    "        self.samples = samples\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        super(MyProgbarLogger, self).on_train_begin(logs)\n",
    "        self.verbose = 1\n",
    "        self.extra_log_values = []\n",
    "        self.params['samples'] = self.samples\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if self.seen < self.target:\n",
    "            self.log_values = []\n",
    "            self.extra_log_values = []\n",
    "\n",
    "    def append_extra_log_values(self, tuples):\n",
    "        for k, v in tuples:\n",
    "            self.extra_log_values.append((k, v))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        epoch_log = 'Epoch {}/{}'.format(epoch + 1, self.epochs)\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.log_values.append((k, logs[k]))\n",
    "                epoch_log += ' - {}: {:.4f}'.format(k, logs[k])\n",
    "        for k, v in self.extra_log_values:\n",
    "            self.log_values.append((k, v))\n",
    "            epoch_log += ' - {}: {:.4f}'.format(k, float(v))\n",
    "        if self.verbose:\n",
    "            self.progbar.update(self.seen, self.log_values)\n",
    "        benchmark.logger.debug(epoch_log)\n",
    "\n",
    "def add_conv_layer(model, layer_params, input_dim=None, locally_connected=False):\n",
    "    if len(layer_params) == 3: # 1D convolution\n",
    "        filters = layer_params[0]\n",
    "        filter_len = layer_params[1]\n",
    "        stride = layer_params[2]\n",
    "        if locally_connected:\n",
    "            if input_dim:\n",
    "                model.add(LocallyConnected1D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(LocallyConnected1D(filters, filter_len, strides=stride))\n",
    "        else:\n",
    "            if input_dim:\n",
    "                model.add(Conv1D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(Conv1D(filters, filter_len, strides=stride))\n",
    "    elif len(layer_params) == 5: # 2D convolution\n",
    "        filters = layer_params[0]\n",
    "        filter_len = (layer_params[1], layer_params[2])\n",
    "        stride = (layer_params[3], layer_params[4])\n",
    "        if locally_connected:\n",
    "            if input_dim:\n",
    "                model.add(LocallyConnected2D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(LocallyConnected2D(filters, filter_len, strides=stride))\n",
    "        else:\n",
    "            if input_dim:\n",
    "                model.add(Conv2D(filters, filter_len, strides=stride, input_shape=(input_dim, 1)))\n",
    "            else:\n",
    "                model.add(Conv2D(filters, filter_len, strides=stride))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29df13da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:\n",
      "{'activation': 'relu',\n",
      " 'batch_normalization': False,\n",
      " 'batch_size': 100,\n",
      " 'category_cutoffs': [0.0],\n",
      " 'cell_features': ['expression'],\n",
      " 'cell_noise_sigma': 0.0,\n",
      " 'data_type': <class 'numpy.float32'>,\n",
      " 'dense': [1000, 500, 100, 50],\n",
      " 'dropout': 0.1,\n",
      " 'drug_features': ['descriptors'],\n",
      " 'epochs': 50,\n",
      " 'experiment_id': 'EXP000',\n",
      " 'feature_subsample': 0,\n",
      " 'initialization': 'normal',\n",
      " 'learning_rate': 0.001,\n",
      " 'logfile': None,\n",
      " 'loss': 'mse',\n",
      " 'max_logconc': -4.0,\n",
      " 'min_logconc': -5.0,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000',\n",
      " 'profiling': False,\n",
      " 'rng_seed': 2017,\n",
      " 'run_id': 'RUN000',\n",
      " 'scaling': 'std',\n",
      " 'scramble': False,\n",
      " 'shuffle': False,\n",
      " 'subsample': 'naive_balancing',\n",
      " 'test_cell_split': 0.15,\n",
      " 'timeout': -1,\n",
      " 'train_bool': True,\n",
      " 'val_split': 0.1,\n",
      " 'verbose': None,\n",
      " 'workers': 1}\n"
     ]
    }
   ],
   "source": [
    "gParameters = initialize_parameters()\n",
    "gParameters['epochs'] = 5\n",
    "gParameters['train_steps'] = 100\n",
    "gParameters['val_steps'] = 10\n",
    "gParameters['test_steps'] = 10\n",
    "benchmark.check_params(gParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2345abcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params: {'dense': [1000, 500, 100, 50], 'batch_size': 100, 'epochs': 5, 'activation': 'relu', 'loss': 'mse', 'optimizer': 'sgd', 'learning_rate': 0.001, 'scaling': 'std', 'dropout': 0.1, 'feature_subsample': 0, 'val_split': 0.1, 'rng_seed': 2017, 'initialization': 'normal', 'min_logconc': -5.0, 'max_logconc': -4.0, 'category_cutoffs': [0.0], 'test_cell_split': 0.15, 'cell_features': ['expression'], 'drug_features': ['descriptors'], 'subsample': 'naive_balancing', 'batch_normalization': False, 'cell_noise_sigma': 0.0, 'output_dir': '/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/save/EXP000/RUN000', 'verbose': None, 'logfile': None, 'train_bool': True, 'experiment_id': 'EXP000', 'run_id': 'RUN000', 'shuffle': False, 'profiling': False, 'scramble': False, 'workers': 1, 'data_type': <class 'numpy.float32'>, 'timeout': -1, 'train_steps': 100, 'val_steps': 10, 'test_steps': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 500, 100, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/2216/.conda/envs/Combo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2878: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/2216/.local/lib/python3.6/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3_all_drugs_new_data.py:620: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nci60_filtered['NSC'] = nci60_filtered['NSC'].str.replace('NSC.', '')\n",
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3_all_drugs_new_data.py:622: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nci60_filtered['CELLNAME'] = nci60_filtered['CELLNAME'].str.replace('NCI60.', '')\n",
      "/lustre/schandra_crpl/users/2216/NCI-DOE-Collab-Pilot1-Single-Drug-Response-Predictor/Pilot1/P1B3/p1b3_all_drugs_new_data.py:624: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nci60_filtered['CELLNAME'] = nci60_filtered['CELLNAME'].str.replace('-', '')\n",
      "Loaded 3780148 unique (D, CL) response sets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CELLNAME     AUC\n",
      "NSC                    \n",
      "1          7860  0.9258\n",
      "1          7860  0.9154\n",
      "1          7860  0.9162\n",
      "100044     7860  0.9916\n",
      "100055     7860  0.7956\n",
      "NCI exp dtypes:\n",
      "CELLNAME     object\n",
      "AARS        float64\n",
      "ABCB6       float64\n",
      "ABCC5       float64\n",
      "ABCF1       float64\n",
      "             ...   \n",
      "ZNF395      float64\n",
      "ZNF451      float64\n",
      "ZNF586      float64\n",
      "ZNF589      float64\n",
      "ZW10        float64\n",
      "Length: 955, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distribution of dose response:\n",
      "                AUC\n",
      "count  1.433472e+06\n",
      "mean   9.128660e-01\n",
      "std    1.112186e-01\n",
      "min    0.000000e+00\n",
      "25%    8.762000e-01\n",
      "50%    9.563000e-01\n",
      "75%    9.889000e-01\n",
      "max    1.000000e+00\n",
      "Category cutoffs: [0.0]\n",
      "Dose response bin counts:\n",
      "  Class 0:       0 (0.0000) - between +0.00 and +0.00\n",
      "  Class 1: 1433472 (1.0000) - between +0.00 and +0.01\n",
      "  Total:   1433472\n",
      "Rows in train: 1288887, val: 143209, test: 1376\n",
      "Input features shapes:\n",
      "  cell_expression: (954,)\n",
      "  drug_descriptors: (3809,)\n",
      "Total input dimensions: 4763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2216/.conda/envs/Combo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              4764000   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,319,701\n",
      "Trainable params: 5,319,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs the model using the specified set of parameters\n",
    "\n",
    "Args:\n",
    "   gParameters: a python dictionary containing the parameters (e.g. epoch)\n",
    "   to run the model with.\n",
    "\"\"\"\n",
    "#\n",
    "if 'dense' in gParameters:\n",
    "    dval = gParameters['dense']\n",
    "    if type(dval) != list:\n",
    "        res = list(dval)\n",
    "    #try:\n",
    "        #is_str = isinstance(dval, basestring)\n",
    "    #except NameError:\n",
    "        #is_str = isinstance(dval, str)\n",
    "    #if is_str:\n",
    "        #res = str2lst(dval)\n",
    "        gParameters['dense'] = res\n",
    "    print(gParameters['dense'])\n",
    "\n",
    "if 'conv' in gParameters:\n",
    "    flat = gParameters['conv']\n",
    "    gParameters['conv'] = [flat[i:i+3] for i in range(0, len(flat), 3)]\n",
    "    #conv_list = p1_common.parse_conv_list(gParameters['conv'])\n",
    "    #cval = gParameters['conv']\n",
    "    #try:\n",
    "    #    is_str = isinstance(cval, basestring)\n",
    "    #except NameError:\n",
    "    #    is_str = isinstance(cval, str)\n",
    "    #if is_str:\n",
    "    #    res = str2lst(cval)\n",
    "    #    gParameters['conv'] = res\n",
    "    print('Conv input', gParameters['conv'])\n",
    "# print('Params:', gParameters)\n",
    "# Construct extension to save model\n",
    "ext = benchmark.extension_from_parameters(gParameters, '.keras')\n",
    "logfile = gParameters['logfile'] if gParameters['logfile'] else gParameters['output_dir']+ext+'.log'\n",
    "\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setFormatter(logging.Formatter(\"[%(asctime)s %(process)d] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"))\n",
    "fh.setLevel(logging.DEBUG)\n",
    "\n",
    "sh = logging.StreamHandler()\n",
    "sh.setFormatter(logging.Formatter(''))\n",
    "sh.setLevel(logging.DEBUG if gParameters['verbose'] else logging.INFO)\n",
    "\n",
    "benchmark.logger.setLevel(logging.DEBUG)\n",
    "benchmark.logger.addHandler(fh)\n",
    "benchmark.logger.addHandler(sh)\n",
    "benchmark.logger.info('Params: {}'.format(gParameters))\n",
    "\n",
    "# Get default parameters for initialization and optimizer functions\n",
    "kerasDefaults = candle.keras_default_config()\n",
    "seed = gParameters['rng_seed']\n",
    "\n",
    "# Build dataset loader object\n",
    "loader = benchmark.DataLoader(seed=seed, dtype=gParameters['data_type'],\n",
    "                         val_split=gParameters['val_split'],\n",
    "                         test_cell_split=gParameters['test_cell_split'],\n",
    "                         cell_features=gParameters['cell_features'],\n",
    "                         drug_features=gParameters['drug_features'],\n",
    "                         feature_subsample=gParameters['feature_subsample'],\n",
    "                         scaling=gParameters['scaling'],\n",
    "                         scramble=gParameters['scramble'],\n",
    "                         min_logconc=gParameters['min_logconc'],\n",
    "                         max_logconc=gParameters['max_logconc'],\n",
    "                         subsample=gParameters['subsample'],\n",
    "                         category_cutoffs=gParameters['category_cutoffs'])\n",
    "\n",
    "# Initialize weights and learning rule\n",
    "initializer_weights = candle.build_initializer(gParameters['initialization'], kerasDefaults, seed)\n",
    "initializer_bias = candle.build_initializer('constant', kerasDefaults, 0.)\n",
    "\n",
    "gParameters['learning_rate'] = 0.01\n",
    "gParameters['activation'] = 'tanh'\n",
    "activation = gParameters['activation']\n",
    "\n",
    "\n",
    "\n",
    "# Define model architecture\n",
    "gen_shape = None\n",
    "out_dim = 1\n",
    "\n",
    "model = Sequential()\n",
    "if 'dense' in gParameters: # Build dense layers\n",
    "    for layer in gParameters['dense']:\n",
    "        if layer:\n",
    "            model.add(Dense(layer, input_dim=loader.input_dim,\n",
    "                        kernel_initializer=initializer_weights,\n",
    "                        bias_initializer=initializer_bias))\n",
    "            if gParameters['batch_normalization']:\n",
    "                model.add(BatchNormalization())\n",
    "            model.add(Activation(gParameters['activation']))\n",
    "            if gParameters['dropout']:\n",
    "                model.add(Dropout(gParameters['dropout']))\n",
    "else: # Build convolutional layers\n",
    "    gen_shape = 'add_1d'\n",
    "    layer_list = list(range(0, len(gParameters['conv'])))\n",
    "    lc_flag=False\n",
    "    if 'locally_connected' in gParameters:\n",
    "        lc_flag = True\n",
    "\n",
    "    for l, i in enumerate(layer_list):\n",
    "        if i == 0:\n",
    "            add_conv_layer(model, gParameters['conv'][i], input_dim=loader.input_dim,locally_connected=lc_flag)\n",
    "        else:\n",
    "            add_conv_layer(model, gParameters['conv'][i],locally_connected=lc_flag)\n",
    "        if gParameters['batch_normalization']:\n",
    "                model.add(BatchNormalization())\n",
    "        model.add(Activation(gParameters['activation']))\n",
    "        if gParameters['pool']:\n",
    "            model.add(MaxPooling1D(pool_size=gParameters['pool']))\n",
    "    model.add(Flatten())\n",
    "\n",
    "model.add(Dense(out_dim))\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = candle.build_optimizer(gParameters['optimizer'],\n",
    "                                            gParameters['learning_rate'],\n",
    "                                            kerasDefaults)\n",
    "\n",
    "#gParameters['loss'] = rmse\n",
    "# Compile and display model\n",
    "model.compile(loss=gParameters['loss'], optimizer=optimizer)\n",
    "model.summary()\n",
    "benchmark.logger.debug('Model: {}'.format(model.to_json()))\n",
    "\n",
    "train_gen = benchmark.DataGenerator(loader, batch_size=gParameters['batch_size'], shape=gen_shape, name='train_gen', cell_noise_sigma=gParameters['cell_noise_sigma']).flow()\n",
    "val_gen = benchmark.DataGenerator(loader, partition='val', batch_size=gParameters['batch_size'], shape=gen_shape, name='val_gen').flow()\n",
    "val_gen2 = benchmark.DataGenerator(loader, partition='val', batch_size=gParameters['batch_size'], shape=gen_shape, name='val_gen2').flow()\n",
    "test_gen = benchmark.DataGenerator(loader, partition='test', batch_size=gParameters['batch_size'], shape=gen_shape, name='test_gen').flow()\n",
    "\n",
    "train_steps = int(loader.n_train/gParameters['batch_size'])\n",
    "val_steps = int(loader.n_val/gParameters['batch_size'])\n",
    "test_steps = int(loader.n_test/gParameters['batch_size'])\n",
    "\n",
    "if 'train_steps' in gParameters:\n",
    "    train_steps = gParameters['train_steps']\n",
    "if 'val_steps' in gParameters:\n",
    "    val_steps = gParameters['val_steps']\n",
    "if 'test_steps' in gParameters:\n",
    "    test_steps = gParameters['test_steps']\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=gParameters['output_dir']+'.model'+ext+'.h5', save_best_only=True)\n",
    "progbar = MyProgbarLogger(train_steps * gParameters['batch_size'])\n",
    "loss_history = MyLossHistory(progbar=progbar, val_gen=val_gen2, test_gen=test_gen,\n",
    "                        val_steps=val_steps, test_steps=test_steps,\n",
    "                        metric=gParameters['loss'], category_cutoffs=gParameters['category_cutoffs'],\n",
    "                        ext=ext, pre=gParameters['output_dir'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05e4be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2216/.conda/envs/Combo/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 82s 8ms/step - loss: 0.0724 - val_loss: 7.7196e-04 - val_acc: 0.8010 - test_loss: 0.0025 - test_acc: 0.9920\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 69s 7ms/step - loss: 0.0157 - val_loss: 0.0012 - val_acc: 0.9770 - test_loss: 0.0013 - test_acc: 1.0000\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 69s 7ms/step - loss: 0.0102 - val_loss: 3.2772e-04 - val_acc: 0.3720 - test_loss: 2.3871e-04 - test_acc: 0.2140\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 69s 7ms/step - loss: 0.0079 - val_loss: 2.2484e-04 - val_acc: 0.1040 - test_loss: 1.9101e-04 - test_acc: 0.2000\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 69s 7ms/step - loss: 0.0065 - val_loss: 1.7414e-05 - val_acc: 0.9540 - test_loss: 7.2104e-06 - test_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Seed random generator for training\n",
    "np.random.seed(seed)\n",
    "\n",
    "candleRemoteMonitor = candle.CandleRemoteMonitor(params=gParameters)\n",
    "\n",
    "history = model.fit_generator(train_gen, train_steps,\n",
    "                    epochs=gParameters['epochs'],\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    verbose=0,\n",
    "                    callbacks=[checkpointer, loss_history, progbar, candleRemoteMonitor],\n",
    "                    )\n",
    "\n",
    "benchmark.logger.removeHandler(fh)\n",
    "benchmark.logger.removeHandler(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5993557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "val_data = pd.read_csv('~/xgboost-single-drug-reponse-prediction/data/val_data_nci60.csv', sep=',')\n",
    "val_data = val_data.dropna()\n",
    "\n",
    "val_auc = val_data['AUC'].to_numpy()\n",
    "val_drugs = val_data['NSC']\n",
    "\n",
    "val_test = val_data.drop(['SOURCE', 'CELLNAME', 'NSC', 'AUC'], 1)\n",
    "val_test = val_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e000ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared:  -29.9289960268995\n",
      "RMSE:  0.8143571424352765\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(val_test)\n",
    "r_squared = r2_score(val_auc, y_pred)\n",
    "print(\"R-squared: \", r_squared)\n",
    "\n",
    "mse = mean_squared_error(val_auc, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc7ddf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>CELLNAME</th>\n",
       "      <th>NSC</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AARS</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>ABCF3</th>\n",
       "      <th>ABHD4</th>\n",
       "      <th>...</th>\n",
       "      <th>DLS_01</th>\n",
       "      <th>DLS_02</th>\n",
       "      <th>DLS_03</th>\n",
       "      <th>DLS_04</th>\n",
       "      <th>DLS_05</th>\n",
       "      <th>DLS_06</th>\n",
       "      <th>DLS_07</th>\n",
       "      <th>DLS_cons</th>\n",
       "      <th>LLS_01</th>\n",
       "      <th>LLS_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>NCI60</td>\n",
       "      <td>HOP62</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.207705</td>\n",
       "      <td>-0.104068</td>\n",
       "      <td>-0.219154</td>\n",
       "      <td>0.089780</td>\n",
       "      <td>-0.133923</td>\n",
       "      <td>0.057540</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>NCI60</td>\n",
       "      <td>MALME3M</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>-0.152366</td>\n",
       "      <td>-0.011850</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.026186</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>0.253913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>NCI60</td>\n",
       "      <td>MCF7</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>-0.044345</td>\n",
       "      <td>0.095241</td>\n",
       "      <td>0.017781</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.087492</td>\n",
       "      <td>-0.642860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>NCI60</td>\n",
       "      <td>RPMI8226</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.198703</td>\n",
       "      <td>-0.461040</td>\n",
       "      <td>-0.171438</td>\n",
       "      <td>0.085915</td>\n",
       "      <td>0.022913</td>\n",
       "      <td>-0.492307</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>NCI60</td>\n",
       "      <td>SR</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>-0.210877</td>\n",
       "      <td>-0.187361</td>\n",
       "      <td>-0.069424</td>\n",
       "      <td>0.167091</td>\n",
       "      <td>0.313520</td>\n",
       "      <td>-0.394120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SOURCE  CELLNAME     NSC     AUC      AARS     ABCB6     ABCC5     ABCF1  \\\n",
       "769  NCI60     HOP62  141993  0.9161  0.207705 -0.104068 -0.219154  0.089780   \n",
       "770  NCI60   MALME3M  141993  0.8999 -0.152366 -0.011850 -0.000318 -0.026186   \n",
       "771  NCI60      MCF7  141993  0.9327 -0.044345  0.095241  0.017781  0.027932   \n",
       "772  NCI60  RPMI8226  141993  0.8790  0.198703 -0.461040 -0.171438  0.085915   \n",
       "773  NCI60        SR  141993  0.9267 -0.210877 -0.187361 -0.069424  0.167091   \n",
       "\n",
       "        ABCF3     ABHD4  ...  DLS_01  DLS_02  DLS_03  DLS_04  DLS_05  DLS_06  \\\n",
       "769 -0.133923  0.057540  ...     1.0    0.83     1.0     0.6     0.5    0.83   \n",
       "770  0.055203  0.253913  ...     1.0    0.83     1.0     0.6     0.5    0.83   \n",
       "771  0.087492 -0.642860  ...     1.0    0.83     1.0     0.6     0.5    0.83   \n",
       "772  0.022913 -0.492307  ...     1.0    0.83     1.0     0.6     0.5    0.83   \n",
       "773  0.313520 -0.394120  ...     1.0    0.83     1.0     0.6     0.5    0.83   \n",
       "\n",
       "     DLS_07  DLS_cons  LLS_01  LLS_02  \n",
       "769     1.0      0.82     0.5    0.88  \n",
       "770     1.0      0.82     0.5    0.88  \n",
       "771     1.0      0.82     0.5    0.88  \n",
       "772     1.0      0.82     0.5    0.88  \n",
       "773     1.0      0.82     0.5    0.88  \n",
       "\n",
       "[5 rows x 4767 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf7f4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELLNAME</th>\n",
       "      <th>DRUG</th>\n",
       "      <th>AUC_true</th>\n",
       "      <th>AUC_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>HOP62</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>MALME3M</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>MCF7</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>RPMI8226</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>SR</td>\n",
       "      <td>141993</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>SR</td>\n",
       "      <td>57197</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>HOP62</td>\n",
       "      <td>633782</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.010873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>HOP92</td>\n",
       "      <td>633782</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.010873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>RPMI8226</td>\n",
       "      <td>633782</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.010873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>SR</td>\n",
       "      <td>633782</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>0.010873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1014 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CELLNAME    DRUG  AUC_true  AUC_pred\n",
       "769      HOP62  141993    0.9161  0.019326\n",
       "770    MALME3M  141993    0.8999  0.019326\n",
       "771       MCF7  141993    0.9327  0.019326\n",
       "772   RPMI8226  141993    0.8790  0.019326\n",
       "773         SR  141993    0.9267  0.019326\n",
       "...        ...     ...       ...       ...\n",
       "2426        SR   57197    0.9983  0.015938\n",
       "2442     HOP62  633782    0.9139  0.010873\n",
       "2443     HOP92  633782    0.3732  0.010873\n",
       "2444  RPMI8226  633782    0.8685  0.010873\n",
       "2445        SR  633782    0.9126  0.010873\n",
       "\n",
       "[1014 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nci60_auc_pred = pd.DataFrame(val_data['CELLNAME'])\n",
    "nci60_auc_pred.insert(1, 'AUC_pred', y_pred)\n",
    "nci60_auc_pred.insert(1, 'DRUG', val_drugs)\n",
    "nci60_auc_pred.insert(2, 'AUC_true', val_auc)\n",
    "nci60_auc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f30e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Combo] *",
   "language": "python",
   "name": "conda-env-.conda-Combo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
